# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

# Pull request against these branches will trigger this build
pr:
- master
- staging
- contrib

# Any commit to this branch will trigger the build.
trigger:
- master
- staging
- contrib

jobs:
- job: setup
  timeoutInMinutes: 10
  displayName: Setup
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      # terminate as soon as any internal script fails
      set -e
      
      echo "Running setup..."
      pwd
      ls
      git branch
      uname -ra

      ./scripts/env_reinstall.sh
  
      # use hardcoded root for now because not sure how env changes under ADO policy
      DATA_ROOT="/home/alfred/data_dynamic"

      ./tests/cicd/src/scripts/get_data_for_builds.sh ${DATA_ROOT}

      # copy your model files like so - using dummy file to illustrate
      azcopy --quiet --source:https://$(storagename).blob.core.windows.net/models/model --source-key $(storagekey) --destination /home/alfred/models/your_model_name


- job: unit_tests_job
  dependsOn: setup
  timeoutInMinutes: 5
  displayName: Unit Tests Job
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      echo "Starting unit tests"
      source activate seismic-interpretation
      pytest --durations=0 cv_lib/tests/
      echo "Unit test job passed"
    

###################################################################################################
# LOCAL PATCH JOBS
###################################################################################################

- job: hrnet_penobscot
  dependsOn: setup
  timeoutInMinutes: 5
  displayName: hrnet penobscot
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      conda env list
      source activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/penobscot/local      
      python train.py 'DATASET.ROOT' '/home/alfred/data_dynamic/penobscot' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1 \
                      'TRAIN.DEPTH' 'section' \
                      'MODEL.PRETRAINED' '/home/alfred/models/hrnetv2_w48_imagenet_pretrained.pth' \
                      'OUTPUT_DIR' 'output' 'TRAIN.MODEL_DIR' 'section_depth' \
                      --cfg=configs/hrnet.yaml --debug
      # find the latest model which we just trained
      model=$(ls -td output/hrnet/section_depth/* | head -1)
      echo ${model}
      # # try running the test script
      python test.py 'DATASET.ROOT' '/home/alfred/data_dynamic/penobscot' \
                     'MODEL.PRETRAINED' '/home/alfred/models/hrnetv2_w48_imagenet_pretrained.pth' \
                     'TEST.MODEL_PATH' ${model}/seg_hrnet_running_model_1.pth \
                     --cfg=configs/hrnet.yaml  --debug

- job: seresnet_unet_penobscot
  dependsOn: setup
  timeoutInMinutes: 5
  displayName: seresnet_unet penobscot
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      conda env list
      source activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/penobscot/local      
      python train.py 'DATASET.ROOT' '/home/alfred/data_dynamic/penobscot' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1 \
                      'TRAIN.DEPTH' 'section' \
                      'OUTPUT_DIR' 'output' 'TRAIN.MODEL_DIR' 'section_depth' \
                      --cfg=configs/seresnet_unet.yaml --debug
      # find the latest model which we just trained
      model=$(ls -td output/seresnet_unet/section_depth/* | head -1)
      echo ${model}
      # try running the test script
      python test.py 'DATASET.ROOT' '/home/alfred/data_dynamic/penobscot' 'TEST.MODEL_PATH' ${model}/resnet_unet_running_model_1.pth --cfg=configs/seresnet_unet.yaml  --debug

- job: hrnet_dutchf3_patch
  dependsOn: setup
  timeoutInMinutes: 5
  displayName: hrnet dutchf3 patch
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      source activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/local      
      python train.py 'DATASET.ROOT' '/home/alfred/data_dynamic/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1 \
                      'TRAIN.DEPTH' 'section' \
                      'MODEL.PRETRAINED' '/home/alfred/models/hrnetv2_w48_imagenet_pretrained.pth' \
                      'OUTPUT_DIR' 'output' 'TRAIN.MODEL_DIR' 'section_depth' \
                      --cfg=configs/hrnet.yaml --debug
      # find the latest model which we just trained
      model=$(ls -td output/hrnet/section_depth/* | head -1)
      echo ${model}
      # try running the test script
      python test.py 'DATASET.ROOT' '/home/alfred/data_dynamic/dutch_f3/data' \
                     'MODEL.PRETRAINED' '/home/alfred/models/hrnetv2_w48_imagenet_pretrained.pth' \
                     'TEST.MODEL_PATH' ${model}/seg_hrnet_running_model_1.pth \
                     --cfg=configs/hrnet.yaml --debug

- job: unet_dutchf3
  dependsOn: setup
  timeoutInMinutes: 5
  displayName: unet dutchf3
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      source activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/local      
      python train.py 'DATASET.ROOT' '/home/alfred/data_dynamic/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1 \
                      'TRAIN.DEPTH' 'section' \
                      'OUTPUT_DIR' 'output' 'TRAIN.MODEL_DIR' 'section_depth' \
                      --cfg=configs/unet.yaml --debug
      # find the latest model which we just trained
      model=$(ls -td output/unet/section_depth/* | head -1)
      echo ${model}
      # try running the test script
      python test.py  'DATASET.ROOT' '/home/alfred/data_dynamic/dutch_f3/data' 'TEST.MODEL_PATH' ${model}/resnet_unet_running_model_1.pth --cfg=configs/unet.yaml --debug

- job: seresnet_unet_dutchf3
  dependsOn: setup
  timeoutInMinutes: 5
  displayName: seresnet unet dutchf3
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      source activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/local      
      python train.py 'DATASET.ROOT' '/home/alfred/data_dynamic/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1 \
                      'TRAIN.DEPTH' 'section' \
                      'OUTPUT_DIR' 'output' 'TRAIN.MODEL_DIR' 'section_depth' \
                      --cfg=configs/seresnet_unet.yaml --debug
      # find the latest model which we just trained
      model=$(ls -td output/seresnet_unet/section_depth/* | head -1)
      # try running the test script
      python test.py 'DATASET.ROOT' '/home/alfred/data_dynamic/dutch_f3/data' 'TEST.MODEL_PATH' ${model}/resnet_unet_running_model_1.pth --cfg=configs/seresnet_unet.yaml --debug

- job: patch_deconvnet_dutchf3
  dependsOn: setup
  timeoutInMinutes: 5
  displayName: patch deconvnet dutchf3
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      source activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/local      
      python train.py 'DATASET.ROOT' '/home/alfred/data_dynamic/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1 \
                      'TRAIN.DEPTH' 'none' \
                      'OUTPUT_DIR' 'output' 'TRAIN.MODEL_DIR' 'no_depth' \
                      --cfg=configs/patch_deconvnet.yaml --debug
      # find the latest model which we just trained
      model=$(ls -td output/patch_deconvnet/no_depth/* | head -1)
      # try running the test script
      python test.py 'DATASET.ROOT' '/home/alfred/data_dynamic/dutch_f3/data' 'VALIDATION.BATCH_SIZE_PER_GPU' 1 'TEST.MODEL_PATH' ${model}/patch_deconvnet_running_model_1.pth --cfg=configs/patch_deconvnet.yaml --debug

- job: patch_deconvnet_skip_dutchf3
  dependsOn: setup
  timeoutInMinutes: 5
  displayName: patch deconvnet skip dutchf3
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      source activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/local
      python train.py 'DATASET.ROOT' '/home/alfred/data_dynamic/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1 \
                      'TRAIN.DEPTH' 'none' \
                      'OUTPUT_DIR' 'output' 'TRAIN.MODEL_DIR' 'no_depth' \
                      --cfg=configs/patch_deconvnet_skip.yaml --debug
      # find the latest model which we just trained
      model=$(ls -td output/patch_deconvnet_skip/no_depth/* | head -1)
      # try running the test script
      python test.py 'DATASET.ROOT' '/home/alfred/data_dynamic/dutch_f3/data' 'VALIDATION.BATCH_SIZE_PER_GPU' 1 'TEST.MODEL_PATH' ${model}/patch_deconvnet_skip_running_model_1.pth --cfg=configs/patch_deconvnet_skip.yaml --debug


###################################################################################################
# DISTRIBUTED PATCH JOBS
###################################################################################################

- job: hrnet_dutchf3_dist
  dependsOn: setup
  timeoutInMinutes: 5
  displayName: hrnet dutchf3 distributed
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      source activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/distributed      
      python -m torch.distributed.launch --nproc_per_node=$(nproc) train.py \
                      'DATASET.ROOT' '/home/alfred/data_dynamic/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1 \
                      'TRAIN.DEPTH' 'section' \
                      'MODEL.PRETRAINED' '/home/alfred/models/hrnetv2_w48_imagenet_pretrained.pth' \
                      'OUTPUT_DIR' 'output' 'TRAIN.MODEL_DIR' 'section_depth' \
                      --cfg=configs/hrnet.yaml --debug

- job: unet_dutchf3_dist
  dependsOn: setup
  timeoutInMinutes: 5
  displayName: unet dutchf3 distributed
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      source activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/distributed      
      python -m torch.distributed.launch --nproc_per_node=$(nproc) train.py \
                      'DATASET.ROOT' '/home/alfred/data_dynamic/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1 \
                      'TRAIN.DEPTH' 'section' \
                      'OUTPUT_DIR' 'output' 'TRAIN.MODEL_DIR' 'section_depth' \
                      --cfg=configs/unet.yaml --debug

- job: seresnet_unet_dutchf3_dist
  dependsOn: setup
  timeoutInMinutes: 5
  displayName: seresnet unet dutchf3 distributed
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      source activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/distributed      
      python -m torch.distributed.launch --nproc_per_node=$(nproc) train.py \
                      'DATASET.ROOT' '/home/alfred/data_dynamic/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1 \
                      'TRAIN.DEPTH' 'section' \
                      'OUTPUT_DIR' 'output' 'TRAIN.MODEL_DIR' 'section_depth' \
                      --cfg=configs/seresnet_unet.yaml --debug

- job: patch_deconvnet_dutchf3_dist
  dependsOn: setup
  timeoutInMinutes: 5
  displayName: patch deconvnet dutchf3 distributed
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      source activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/distributed      
      python -m torch.distributed.launch --nproc_per_node=$(nproc) train.py \
                      'DATASET.ROOT' '/home/alfred/data_dynamic/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1 \
                      'TRAIN.DEPTH' 'none' \
                      'OUTPUT_DIR' 'output' 'TRAIN.MODEL_DIR' 'no_depth' \
                      --cfg=configs/patch_deconvnet.yaml --debug

- job: patch_deconvnet_skip_dutchf3_dist
  dependsOn: setup
  timeoutInMinutes: 5
  displayName: patch deconvnet skip dutchf3 distributed
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      source activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/distributed      
      python -m torch.distributed.launch --nproc_per_node=$(nproc) train.py \
                      'DATASET.ROOT' '/home/alfred/data_dynamic/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1 \
                      'TRAIN.DEPTH' 'none' \
                      'OUTPUT_DIR' 'output' 'TRAIN.MODEL_DIR' 'no_depth' \
                      --cfg=configs/patch_deconvnet_skip.yaml --debug

###################################################################################################
# LOCAL SECTION JOBS
###################################################################################################

- job: section_deconvnet_skip
  dependsOn: setup
  timeoutInMinutes: 5
  displayName: section deconvnet skip
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      source activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/dutchf3_section/local
      python train.py 'DATASET.ROOT' '/home/alfred/data_dynamic/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1 \
                      'TRAIN.DEPTH' 'none' \
                      'OUTPUT_DIR' 'output' 'TRAIN.MODEL_DIR' 'no_depth' \
                      --cfg=configs/section_deconvnet_skip.yaml --debug
      # find the latest model which we just trained
      model=$(ls -td output/section_deconvnet_skip/no_depth/* | head -1)
      echo ${model}
      # try running the test script
      python test.py 'DATASET.ROOT' '/home/alfred/data_dynamic/dutch_f3/data' 'TEST.MODEL_PATH' ${model}/section_deconvnet_skip_running_model_1.pth --cfg=configs/section_deconvnet_skip.yaml --debug


